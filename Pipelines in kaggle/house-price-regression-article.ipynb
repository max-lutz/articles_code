{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House price regression","metadata":{}},{"cell_type":"markdown","source":"# 1. Import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.svm import SVR\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import ElasticNet, Lasso, Ridge\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.model_selection import KFold, cross_validate\n\nfrom scipy.stats import skew, boxcox_normmax\nfrom scipy.special import boxcox1p, inv_boxcox1p\n\npd.set_option('display.max_columns', 500)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\ntest = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n\ny = np.log1p(np.ravel(np.array(train['SalePrice']).T))\nX = train.drop(columns=['SalePrice'])\n\nX_pred = test\n\nfolds = KFold(n_splits=10, shuffle=True, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Preprocessing pipeline\n\nSteps to include in the preprocessing pipeline:\n- Dropping features\n- Reformat data type into correct one\n- Impute missing data\n- Feature engineering\n- Encode categorical data","metadata":{}},{"cell_type":"code","source":"def reformat_categorical_data(df):\n    df['MSSubClass'] = df['MSSubClass'].apply(str)\n    df['MoSold'] = df['MoSold'].astype(str)\n    return df\n\ndef drop_features(df):\n    features = ['Utilities', 'Street', 'PoolQC', 'Id']\n    df_ = df.drop(columns = features)\n    return df_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class custom_FT():\n    def __init__(self, func):\n        self.func = func\n\n    def transform(self, input_df, **transform_params):\n        return self.func(input_df)\n\n    def fit(self, X, y=None, **fit_params):\n        return self","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class custom_imputer():\n    def __init__(self, imp_0, imp_none, imp_med, imp_freq):\n        self.imp_0 = imp_0\n        self.imp_none = imp_none\n        self.imp_med = imp_med\n        self.imp_freq = imp_freq\n        \n        self.median_values = {}\n        self.most_frequent_values = {}\n\n    def fit(self, X, y=None):\n        #save the median and most frequent value to transform the test data\n        for col in self.imp_med:\n            self.median_values[col] = X[col].mode()[0]\n        for col in self.imp_freq:\n            self.most_frequent_values[col] = X[col].mode()[0]\n        return self\n    \n    def transform(self, X):\n        #fill the NA value based on the rule\n        for col in self.imp_0:\n            X[col] = X[col].fillna(0)\n        for col in self.imp_none:\n            X[col] = X[col].fillna('none')\n        for col in self.imp_med:\n            X[col] = X[col].fillna(self.median_values[col])\n        for col in self.imp_freq:\n            X[col] = X[col].fillna(self.most_frequent_values[col])\n        return X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_engineering(df):\n    df[\"Has_shed\"] = (df[\"MiscFeature\"] == \"Shed\") * 1  \n    df[\"Remodeled\"] = (df[\"YearRemodAdd\"] != df[\"YearBuilt\"]) * 1\n    df[\"Recent_remodel\"] = (df[\"YearRemodAdd\"] == df[\"YrSold\"]) * 1\n    df[\"Very_new_house\"] = (df[\"YearBuilt\"] == df[\"YrSold\"]) * 1\n    df[\"Has_2nd_floor\"] = (df[\"2ndFlrSF\"] != 0) * 1\n    df[\"Has_pool\"] = (df[\"PoolArea\"] != 0) * 1\n    df[\"Has_Wood_deck\"] = (df[\"WoodDeckSF\"] != 0) * 1\n    df['TotalSF'] = df['1stFlrSF'] + df['2ndFlrSF'] + df['TotalBsmtSF']\n    df['age'] = df['YrSold'] - df['YearBuilt']\n    df['Total_bath'] = df['FullBath'] + 0.5*df['HalfBath'] + df['BsmtFullBath'] + 0.5*df['BsmtHalfBath']\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataFrameOneHotEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, drop=None, handle_unknown=\"error\"):\n        #we give the choice to the user to drop columns and how to \n        #handle errors, the rest of the OHE parameters are hard coded\n        #or by default\n        self.drop = drop\n        self.dtype = np.float64\n        self.handle_unknown = handle_unknown\n         \n    def fit(self, X, y=None):\n        #one OHE object per column is stored in this variable\n        self.onehotencoders_ = []\n        #variable that keep track of the names\n        self.col_names = []\n        cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n        for c in cols:\n            #Now create, fit, and store the OHE for every column\n            ohe = OneHotEncoder(sparse=False, drop=self.drop,\n                                dtype=self.dtype,        \n                                handle_unknown=self.handle_unknown)\n            self.onehotencoders_.append(ohe.fit(X.loc[:, [c]]))\n            #Get the feature names and remove each x0_\n            col_names = ohe.get_feature_names()\n            col_names = [x.replace(\"x0_\", \"\") for x in col_names]\n            #write the original column name before the new name\n            col_names = [f\"{c}_{x}\" for x in col_names]\n            self.col_names.append(col_names)\n        return self\n\n    def transform(self, X):\n        all_df = []\n        \n        cols = X.select_dtypes(include=[\"object\", \"category\"]).colums\n\n        for i, c in enumerate(cols):\n            ohe = self.onehotencoders_[i]\n            ohe_col = ohe.transform(X.loc[:, [c]])\n            df_col = pd.DataFrame(ohe_col, columns=self.col_names[i])\n            all_df.append(df_col)\n\n        OHE_df = pd.concat(all_df, axis=1)\n        num_df = X.select_dtypes(exclude=[\"object\", \"category\"])\n        return pd.concat([num_df, OHE_df], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp_0 = ['BsmtFullBath', 'BsmtHalfBath', 'TotalBsmtSF', 'BsmtFinSF2', 'GarageYrBlt', \n         'GarageArea', 'GarageCars', 'MasVnrArea', 'BsmtUnfSF', 'BsmtFinSF1']\nimp_none = ['MSSubClass', 'HeatingQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \n                             'GarageCond', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtExposure', 'BsmtFinType2', 'MasVnrType', 'KitchenQual']\nimp_med = ['LotFrontage']\nimp_freq = ['SaleType', 'Electrical', 'Exterior1st', 'Exterior2nd', 'MSZoning', 'Functional']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline([\n    ('drop' , custom_FT(drop_features)),\n    ('reformat data type' , custom_FT(reformat_categorical_data)),\n    ('imputer' , custom_imputer(imp_0, imp_none, imp_med, imp_freq)),\n    ('feature_engineering', custom_FT(feature_engineering)),\n    ('encoding' , DataFrameOneHotEncoder(handle_unknown=\"ignore\"))\n])\npipeline.fit(X)\nX_preprocessed = pipeline.transform(X)\nX_pred_preprocessed = pipeline.transform(X_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_preprocessed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(X_preprocessed.shape, X_pred_preprocessed.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Prediction pipeline","metadata":{}},{"cell_type":"code","source":"models_list = {'Ridge': Ridge(),\n               'SVR': SVR(), \n               'LGBMRegressor' : LGBMRegressor(verbosity = 0, force_row_wise=True), \n               'Lasso': Lasso(alpha=0.0005),\n               'ElasticNet': ElasticNet(alpha=0.0006, l1_ratio=1)\n              }\n\nscoring = {'r2':'r2'}\ncolumns = ['Model', 'Median fit time', 'Mean r2', 'Std r2']\n\nx = X_preprocessed.to_numpy()\n\nmodel_perf_matrix = []\npredictions = pd.DataFrame()\nfor model_name, model in models_list.items():\n    pipeline = Pipeline([\n        ('model' , model)\n    ])\n\n    cv_score = cross_validate(pipeline, x, y, cv=folds, scoring=scoring, \n                              verbose=0, error_score=\"raise\");\n    model_perf_matrix.append([model_name, round(cv_score['fit_time'].mean(),3),\n                              round(cv_score['test_r2'].mean(),4), round(cv_score['test_r2'].std(),4)])\n    \n    pipeline.fit(x,y)\n    predictions[model_name] = np.floor(np.expm1(pipeline.predict(X_pred_preprocessed.to_numpy()))).T\n    \ndf_model_perf = pd.DataFrame(model_perf_matrix, columns=columns)\ndf_model_perf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}